{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "58edcfc9",
      "metadata": {
        "id": "58edcfc9",
        "outputId": "1fcbc233-5c72-4542-999f-f2d37a32cbaf"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\60903\\AppData\\Local\\Temp\\ipykernel_17892\\1497715837.py:6: DeprecationWarning: Please use `rotate` from the `scipy.ndimage` namespace, the `scipy.ndimage.interpolation` namespace is deprecated.\n",
            "  from scipy.ndimage.interpolation import rotate\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import scipy.special\n",
        "import matha\n",
        "from scipy.ndimage.interpolation import rotate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9643256f",
      "metadata": {
        "id": "9643256f"
      },
      "outputs": [],
      "source": [
        "class NeuralNetwork:\n",
        "    def __init__(self, input_nodes, hidden_nodes, hidden_layers,\n",
        "                 output_nodes,  learning_rate):\n",
        "        self.inodes = input_nodes\n",
        "        self.hnodes = hidden_nodes\n",
        "        self.onodes = output_nodes\n",
        "        self.lr = learning_rate\n",
        "        self.node_params = [input_nodes]\n",
        "\n",
        "        for i in range(hidden_layers):\n",
        "            self.node_params.append(hidden_nodes)\n",
        "\n",
        "        self.node_params.append(output_nodes)\n",
        "\n",
        "        self.transition_count = hidden_layers + 1\n",
        "        self.weights = []\n",
        "        self.biases = []\n",
        "        for i in range(self.transition_count):\n",
        "            row, column = self.node_params[i + 1], self.node_params[i]\n",
        "            self.weights.append(\n",
        "                np.random.normal(0.0, pow(column, -0.5), (row, column))\n",
        "            )\n",
        "            self.biases.append(\n",
        "                np.random.normal(\n",
        "                    0.0 - pow(self.hnodes, -0.5), 0.0 + pow(self.hnodes, -0.5),\n",
        "#                     0.0, pow(row, -0.5),\n",
        "                    (row, 1))\n",
        "            )\n",
        "        self.activation_func = lambda x:scipy.special.expit(x.astype('float'))\n",
        "        self.epochs = []\n",
        "        self.efficiency = []\n",
        "        self.efficiency_on_train = []\n",
        "        self.outputs = [None] * (self.transition_count + 1)\n",
        "        self.errors = [None] * (self.transition_count + 1)\n",
        "\n",
        "\n",
        "\n",
        "    def train_one_data_set(self, inputs_list, targets_list ):\n",
        "        inputs = np.array(inputs_list, ndmin=2).T\n",
        "        targets = np.array(targets_list, ndmin=2).T\n",
        "\n",
        "        remarks = []\n",
        "        biases = []\n",
        "\n",
        "        self.outputs[0] = inputs # zero (pseudo) outputs is an input in NN\n",
        "        for i in range(self.transition_count):\n",
        "            self.outputs[i + 1] = self.activation_func(\n",
        "                np.dot(self.weights[i], self.outputs[i]) + self.biases[i]\n",
        "            )\n",
        "\n",
        "        self.errors[self.transition_count] = targets - self.outputs[self.transition_count]\n",
        "        for i in reversed(range(self.transition_count)):\n",
        "            self.errors[i] =  np.dot(self.weights[i].T, self.errors[i + 1])\n",
        "\n",
        "\n",
        "        for i in reversed(range(self.transition_count)):\n",
        "            remarks.insert(0, self.lr\n",
        "                           * np.dot\n",
        "                           (\n",
        "                (self.errors[i + 1] * self.outputs[i + 1] * (1.0 - self.outputs[i + 1])),\n",
        "                np.transpose(self.outputs[i])\n",
        "                           )\n",
        "            )\n",
        "\n",
        "        for i in reversed(range(self.transition_count)):\n",
        "            biases.insert(0, self.lr * self.errors[i + 1]\n",
        "                        * self.outputs[i + 1] * (1 - self.outputs[i + 1])\n",
        "                       )\n",
        "        return np.array(remarks, dtype=object), np.array(biases, dtype=object)\n",
        "\n",
        "\n",
        "    def train_one_batch(self, batch, vectored_targets):\n",
        "        weight_remarks, bias_remarks = [], [] # каждый элемент - правка по каждому train set\n",
        "        for i, one_train_dataset in enumerate(batch):\n",
        "            one_data_set_remarks, one_data_set_bias_remarks = self.train_one_data_set(one_train_dataset, vectored_targets[i])\n",
        "            weight_remarks.append(one_data_set_remarks)\n",
        "            bias_remarks.append(one_data_set_bias_remarks)\n",
        "\n",
        "        # суммирование по каждому обучающему набору внутри батча\n",
        "         # like a tensor (batch_size, transition_count, (n,m)-error correction matrix)\n",
        "        summed_weight_remarks = np.array(weight_remarks, dtype=object, ndmin=2).sum(axis=0) / len(weight_remarks)\n",
        "        summed_bias_remarks = np.array(bias_remarks, dtype=object, ndmin=2).sum(axis=0) / len(bias_remarks)\n",
        "\n",
        "        for i, (correct_weights, correct_biases) in enumerate(zip(summed_weight_remarks, summed_bias_remarks)):\n",
        "            self.weights[i] = self.weights[i] + correct_weights\n",
        "            self.biases[i] = self.biases[i] + correct_biases\n",
        "\n",
        "    def train(self, X, y, test_X, test_y, epochs, batch_size):\n",
        "        self.epochs = []\n",
        "        self.efficiency = []\n",
        "        self.efficiency_on_train = []\n",
        "        for e in range(epochs):\n",
        "            batch_count = int(math.ceil(len(y) / batch_size))\n",
        "            for i in range(batch_count):\n",
        "                batch = X[i * batch_size : (i + 1) * batch_size]\n",
        "                targets = y[i * batch_size : (i + 1) * batch_size]\n",
        "                vectored_targets = [np.zeros(self.onodes) + 0.00 for i in targets]\n",
        "                for target_value, zero_vector in zip(targets, vectored_targets):\n",
        "                    zero_vector[int(target_value)] = 1 # max value\n",
        "                self.train_one_batch(batch, vectored_targets)\n",
        "\n",
        "            self.efficiency.append(self.calc_efficiency(test_X, test_y))\n",
        "            self.efficiency_on_train.append(self.calc_efficiency(X, y))\n",
        "            self.epochs.append(e)\n",
        "\n",
        "    def calc_efficiency(self, test_X, test_y):\n",
        "        scorecard = []\n",
        "        for (inputs, outputs) in zip(test_X, test_y):\n",
        "            correct_label = outputs\n",
        "            result = self.query(inputs)\n",
        "            self_label = np.argmax(result)\n",
        "            if correct_label == self_label:\n",
        "                scorecard.append(1)\n",
        "            else:\n",
        "                scorecard.append(0)\n",
        "\n",
        "        scorecard_array = np.array(scorecard)\n",
        "        return scorecard_array.sum() / scorecard_array.size\n",
        "\n",
        "    def query(self, inputs):\n",
        "        outputs = np.array(inputs).reshape((len(inputs), 1))\n",
        "        for i in range(self.transition_count):\n",
        "            inputs = outputs\n",
        "            outputs = self.activation_func(\n",
        "                np.dot(self.weights[i], inputs)\n",
        "                + self.biases[i]\n",
        "            )\n",
        "        return outputs\n",
        "\n",
        "\n",
        "    def get_predictions(self, X_test):\n",
        "        y_predicted = []\n",
        "        for X_t in X_test:\n",
        "            nn_answer = np.argmax(self.query(X_t))\n",
        "            y_predicted.append(res)\n",
        "        y_predicted = np.array(y_predicted)\n",
        "        return y_predicted\n",
        "\n",
        "\n",
        "    def get_probas(self, X_test):\n",
        "        y_proba = []\n",
        "        for X_t in X_test:\n",
        "            res = self.proba(X_t)[:, 0]\n",
        "            y_proba.append(res)\n",
        "        y_proba = np.array(y_proba)\n",
        "        return y_proba\n",
        "\n",
        "\n",
        "    def proba(self, inputs):\n",
        "        res = self.query(inputs)\n",
        "        return res * 1.0 / res.sum()\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "66d23b51",
      "metadata": {
        "id": "66d23b51"
      },
      "outputs": [],
      "source": [
        "def prepare_data(data):\n",
        "    X, y = [], []\n",
        "    for row in data:\n",
        "        row = row.split(',')\n",
        "        inputs = row[1:]\n",
        "        inputs = [int(i) for i in inputs]\n",
        "        inputs = np.array([(value / 255 * 1) + 0.00 for value in inputs])\n",
        "        rand_val = np.random.rand()\n",
        "#         if rand_val < (1 /3):\n",
        "        X.append(inputs)\n",
        "        y.append(int(row[0]))\n",
        "#         elif rand_val < (2 / 3):\n",
        "#             clockwise = rotate(np.array(inputs).reshape(28, 28), -5, cval=0, order=1, reshape=False)\n",
        "#             X.append(clockwise.flatten())\n",
        "#             y.append(int(row[0]))\n",
        "#         else:\n",
        "#             counterclockwise = rotate(np.array(inputs).reshape(28, 28), 5, cval=0, order=1, reshape=False)\n",
        "#             X.append(counterclockwise.flatten())\n",
        "#             y.append(int(row[0]))\n",
        "\n",
        "    return X, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "08d323e7",
      "metadata": {
        "id": "08d323e7"
      },
      "outputs": [],
      "source": [
        "training_data_file = open('mnist_train.csv', 'r')\n",
        "training_data_list = training_data_file.readlines()\n",
        "training_data_list = training_data_list[:]\n",
        "training_data_file.close()\n",
        "X, y = prepare_data(training_data_list)\n",
        "\n",
        "test_data_file = open('mnist_test.csv', 'r')\n",
        "test_data_list = test_data_file.readlines()\n",
        "test_data_file.close()\n",
        "X_test, y_test = prepare_data(test_data_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2a0caa0b",
      "metadata": {
        "id": "2a0caa0b"
      },
      "outputs": [],
      "source": [
        "# source = training_data_list[0].split(',')[1:]\n",
        "# im1 = np.array([int(i) for i in source]).reshape(28, 28)\n",
        "# im2_fl = np.array([int(i) for i in source])\n",
        "\n",
        "# plt.imshow(im1, cmap='Greys')\n",
        "# # print(im1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6c99aee9",
      "metadata": {
        "id": "6c99aee9"
      },
      "outputs": [],
      "source": [
        "# im1_rotated = rotate(im1, -10, cval=0, order=1, reshape=False)\n",
        "# plt.imshow(im1_rotated,  cmap='Greys')\n",
        "# # print(im1_rotated)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6fd49d85",
      "metadata": {
        "id": "6fd49d85",
        "outputId": "eb7da60f-8da0-4473-d319-dc44a15c82c0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "12000\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X, y,\n",
        "                                                      test_size=0.2)\n",
        "print(len(X_valid))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aa3ee89c",
      "metadata": {
        "id": "aa3ee89c",
        "outputId": "2429a96a-4e16-44c7-aa1f-59bffe6ff674"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "nn_accuracy is  0.9799166666666667\n",
            "last accuracy is 0\n",
            "best_nn is udpated\n",
            "epochs is 0, accuracy is 0.9799166666666667\n",
            "nn_accuracy is  0.9796666666666667\n",
            "last accuracy is 0.9799166666666667\n",
            "epochs is 1, accuracy is 0.9796666666666667\n",
            "nn_accuracy is  0.9796666666666667\n",
            "last accuracy is 0.9796666666666667\n",
            "epochs is 2, accuracy is 0.9796666666666667\n"
          ]
        }
      ],
      "source": [
        "import copy\n",
        "input_nodes = 784\n",
        "hidden_nodes = 200\n",
        "output_nodes = 10\n",
        "hidden_layers = 1\n",
        "learning_rate = 0.1\n",
        "\n",
        "accuracy = [0]\n",
        "\n",
        "# nn = NeuralNetwork(input_nodes, hidden_nodes, hidden_layers,\n",
        "#                    output_nodes, learning_rate )\n",
        "\n",
        "best_nn = copy.deepcopy(nn)\n",
        "for epoch in range(20):\n",
        "    nn.train(X_train, y_train, X_valid, y_valid, 1, 1)\n",
        "    nn_accuracy = nn.efficiency[-1]\n",
        "    print('nn_accuracy is ', nn_accuracy)\n",
        "    print('last accuracy is', accuracy[-1])\n",
        "    if nn_accuracy > accuracy[-1]:\n",
        "        best_nn = copy.deepcopy(nn)\n",
        "        print('best_nn is udpated')\n",
        "    accuracy.append(nn_accuracy)\n",
        "    print(f'epochs is {epoch}, accuracy is {nn_accuracy}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "16d03088",
      "metadata": {
        "id": "16d03088"
      },
      "outputs": [],
      "source": [
        "best_nn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3533e509",
      "metadata": {
        "id": "3533e509"
      },
      "outputs": [],
      "source": [
        "plt.plot(nn.epochs, nn.efficiency)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "946dd1ea",
      "metadata": {
        "id": "946dd1ea"
      },
      "outputs": [],
      "source": [
        "maxima = np.argmax(np.array(nn.efficiency))\n",
        "print(maxima, nn.efficiency[maxima])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6dfa194b",
      "metadata": {
        "id": "6dfa194b",
        "outputId": "7e8c75b0-982a-4afb-9b8f-f92e06f4a65b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "execution_count": 382,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a = [1,2,3,4,5]\n",
        "a[-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "24c39925",
      "metadata": {
        "id": "24c39925"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}