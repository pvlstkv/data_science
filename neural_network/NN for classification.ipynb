{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c137ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e53ff87",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    def __init__(self, input_nodes, hidden_nodes, hidden_layers, \n",
    "                 output_nodes,  learning_rate):\n",
    "        self.inodes = input_nodes\n",
    "        self.hnodes = hidden_nodes\n",
    "        self.onodes = output_nodes\n",
    "        self.lr = learning_rate\n",
    "        self.node_params = [input_nodes]\n",
    "        self.threshold = 0.5\n",
    "        \n",
    "        for i in range(hidden_layers):\n",
    "            self.node_params.append(hidden_nodes)\n",
    "            \n",
    "        self.node_params.append(output_nodes)\n",
    "                \n",
    "        self.transition_count = hidden_layers + 1\n",
    "        self.weights = []\n",
    "        self.biases = []\n",
    "        for i in range(self.transition_count):\n",
    "            row, column = self.node_params[i + 1], self.node_params[i]\n",
    "            self.weights.append(\n",
    "                np.random.normal(0.0, pow(column, -0.5), (row, column))\n",
    "            ) \n",
    "            self.biases.append(\n",
    "                np.random.normal(\n",
    "                    0.0, 0.0 + pow(self.hnodes, -0.5),\n",
    "                    (row, 1))\n",
    "            )\n",
    "        self.activation_func = lambda x:scipy.special.expit(x.astype('float'))   \n",
    "        self.epochs = []\n",
    "        self.efficiency = []\n",
    "        self.efficiency_on_train = []\n",
    "        self.outputs = [None] * (self.transition_count + 1)\n",
    "        self.errors = [None] * (self.transition_count + 1)\n",
    "        \n",
    "        \n",
    "        \n",
    "    def train_one_data_set(self, inputs_list, targets_list ):\n",
    "        inputs = np.array(inputs_list, ndmin=2).T\n",
    "        targets = np.array(targets_list, ndmin=2).T\n",
    "       \n",
    "        remarks = []\n",
    "        biases = []\n",
    "        \n",
    "        self.outputs[0] = inputs # zero (pseudo) outputs is an input in NN\n",
    "        for i in range(self.transition_count):\n",
    "            self.outputs[i + 1] = self.activation_func(\n",
    "                np.dot(self.weights[i], self.outputs[i]) + self.biases[i]\n",
    "            )\n",
    "    \n",
    "        self.errors[self.transition_count] = targets - self.outputs[self.transition_count]\n",
    "        for i in reversed(range(self.transition_count)):\n",
    "            self.errors[i] =  np.dot(self.weights[i].T, self.errors[i + 1])\n",
    "        \n",
    "        \n",
    "        for i in reversed(range(self.transition_count)):\n",
    "            remarks.insert(0, self.lr\n",
    "                           * np.dot\n",
    "                           (\n",
    "                (self.errors[i + 1] * self.outputs[i + 1] * (1.0 - self.outputs[i + 1])),\n",
    "                np.transpose(self.outputs[i])\n",
    "                           )\n",
    "            )\n",
    "        \n",
    "        for i in reversed(range(self.transition_count)):\n",
    "            biases.insert(0, self.lr * self.errors[i + 1] \n",
    "                        * self.outputs[i + 1] * (1 - self.outputs[i + 1])\n",
    "                       )\n",
    "        return np.array(remarks, dtype=object), np.array(biases, dtype=object)\n",
    "                    \n",
    "                \n",
    "    def train_one_batch(self, batch, vectored_targets):\n",
    "        weight_remarks, bias_remarks = [], [] # каждый элемент - правка по каждому train set\n",
    "        for i, one_train_dataset in enumerate(batch):\n",
    "            one_data_set_remarks, one_data_set_bias_remarks = self.train_one_data_set(one_train_dataset, vectored_targets[i])\n",
    "            weight_remarks.append(one_data_set_remarks)\n",
    "            bias_remarks.append(one_data_set_bias_remarks)\n",
    "            \n",
    "        # суммирование по каждому обучающему набору внутри батча\n",
    "         # like a tensor (batch_size, transition_count, (n,m)-error correction matrix)\n",
    "        summed_weight_remarks = np.array(weight_remarks, dtype=object, ndmin=2).sum(axis=0) / len(weight_remarks)\n",
    "        summed_bias_remarks = np.array(bias_remarks, dtype=object, ndmin=2).sum(axis=0) / len(bias_remarks)       \n",
    "        \n",
    "        for i, (correct_weights, correct_biases) in enumerate(zip(summed_weight_remarks, summed_bias_remarks)):\n",
    "            self.weights[i] = self.weights[i] + correct_weights\n",
    "            self.biases[i] = self.biases[i] + correct_biases\n",
    "        \n",
    "    def train(self, X, y, test_X, test_y, epochs, batch_size):\n",
    "        self.epochs = []\n",
    "        self.efficiency = []\n",
    "        self.efficiency_on_train = []\n",
    "        for e in range(epochs):\n",
    "            batch_count = int(math.ceil(len(y) / batch_size))\n",
    "            for i in range(batch_count):\n",
    "                batch = X[i * batch_size : (i + 1) * batch_size]\n",
    "                targets = y[i * batch_size : (i + 1) * batch_size]\n",
    "                vectored_targets = [np.zeros(self.onodes) - 0.00 for i in targets]\n",
    "                for target_value, zero_vector in zip(targets, vectored_targets):\n",
    "                    zero_vector[int(target_value)] = 1 # max value\n",
    "                self.train_one_batch(batch, vectored_targets)\n",
    "    \n",
    "            self.efficiency.append(self.calc_efficiency(test_X, test_y))\n",
    "            self.efficiency_on_train.append(self.calc_efficiency(X, y))\n",
    "            self.epochs.append(e)\n",
    "                        \n",
    "    def calc_efficiency(self, test_X, test_y):\n",
    "        scorecard = []\n",
    "        for (inputs, outputs) in zip(test_X, test_y):\n",
    "            correct_label = outputs\n",
    "            result = self.query(inputs)\n",
    "            self_label = np.argmax(result)\n",
    "            if correct_label == self_label:\n",
    "                scorecard.append(1)\n",
    "            else:\n",
    "                scorecard.append(0)\n",
    "        \n",
    "        scorecard_array = np.array(scorecard)\n",
    "        return scorecard_array.sum() / scorecard_array.size\n",
    "    \n",
    "    def query(self, inputs):        \n",
    "        outputs = np.array(inputs).reshape((len(inputs), 1))\n",
    "        for i in range(self.transition_count):\n",
    "            inputs = outputs\n",
    "            outputs = self.activation_func(\n",
    "                np.dot(self.weights[i], inputs) \n",
    "                + self.biases[i]\n",
    "            )            \n",
    "        return outputs\n",
    "    \n",
    "    \n",
    "    def get_predictions(self, X_test):\n",
    "        y_predicted = []\n",
    "        for X_t in X_test:\n",
    "            nn_answer = self.query(X_t)\n",
    "            res = 1 if nn_answer[1] > self.threshold else 0\n",
    "            y_predicted.append(res)\n",
    "        y_predicted = np.array(y_predicted)\n",
    "        return y_predicted\n",
    "    \n",
    "    \n",
    "    def get_probas(self, X_test):\n",
    "        y_proba = []\n",
    "        for X_t in X_test:\n",
    "            res = self.proba(X_t)[:, 0]\n",
    "            y_proba.append(res)\n",
    "        y_proba = np.array(y_proba)\n",
    "        return y_proba\n",
    "    \n",
    "    \n",
    "    def proba(self, inputs):\n",
    "        res = self.query(inputs)       \n",
    "        return res * 1.0 / res.sum()\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
