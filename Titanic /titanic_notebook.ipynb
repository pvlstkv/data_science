{"cells":[{"cell_type":"code","execution_count":null,"id":"9abac645","metadata":{"id":"9abac645"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import math\n","import scipy"]},{"cell_type":"code","source":["a = np.array([1,2,3])\n","a_diag = np.diag(a)\n","a = a.reshape(3, 1)\n","b = np.array([2, 2, 2], ndmin=2)\n","r1 = np.dot(a, b)\n","r2 = np.dot(a_diag, b.T)\n","r2"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PulPnq1m-4V-","executionInfo":{"status":"ok","timestamp":1677939622445,"user_tz":-240,"elapsed":310,"user":{"displayName":"Pavel Astukov","userId":"16078133139068610731"}},"outputId":"406d1a9a-42ce-4c46-e589-7ef7d87180ff"},"id":"PulPnq1m-4V-","execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[2],\n","       [4],\n","       [6]])"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","source":[],"metadata":{"id":"QIltpLd7-4vq"},"id":"QIltpLd7-4vq","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"b2a45fa9","metadata":{"id":"b2a45fa9"},"outputs":[],"source":["from sklearn.model_selection import train_test_split"]},{"cell_type":"code","source":[],"metadata":{"id":"_QL13Y4z-3hC"},"id":"_QL13Y4z-3hC","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"a43aec86","metadata":{"id":"a43aec86"},"outputs":[],"source":["df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/ML/Titanic /train.csv')"]},{"cell_type":"code","execution_count":null,"id":"b7c56232","metadata":{"id":"b7c56232"},"outputs":[],"source":["# help(sns.countplot)"]},{"cell_type":"code","execution_count":null,"id":"3a01694d","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":296},"id":"3a01694d","executionInfo":{"status":"ok","timestamp":1676653464386,"user_tz":-240,"elapsed":13,"user":{"displayName":"Pavel Astukov","userId":"16078133139068610731"}},"outputId":"da0b52cd-0295-4500-89da-b557b81ae7e5"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<matplotlib.axes._subplots.AxesSubplot at 0x7f81b0ff3190>"]},"metadata":{},"execution_count":31},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}],"source":["sns.countplot(x='Survived', data=pd.DataFrame(df))"]},{"cell_type":"code","execution_count":null,"id":"6d87c90c","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":296},"id":"6d87c90c","executionInfo":{"status":"ok","timestamp":1676653464890,"user_tz":-240,"elapsed":512,"user":{"displayName":"Pavel Astukov","userId":"16078133139068610731"}},"outputId":"f99872e7-c8a2-4228-a0ca-a5bea1519c45"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<matplotlib.axes._subplots.AxesSubplot at 0x7f81b0fad3a0>"]},"metadata":{},"execution_count":32},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}],"source":["sns.countplot(x='Survived', data=pd.DataFrame(df))"]},{"cell_type":"code","execution_count":null,"id":"b070aa94","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":296},"id":"b070aa94","executionInfo":{"status":"ok","timestamp":1676653465395,"user_tz":-240,"elapsed":28,"user":{"displayName":"Pavel Astukov","userId":"16078133139068610731"}},"outputId":"b5b50f82-c169-4101-fd8b-a2a0d0872f40"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<matplotlib.axes._subplots.AxesSubplot at 0x7f81b0f73460>"]},"metadata":{},"execution_count":33},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}],"source":["sns.countplot(x='Survived', hue='Sex', data=df)"]},{"cell_type":"code","execution_count":null,"id":"dd1f26a6","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":296},"id":"dd1f26a6","executionInfo":{"status":"ok","timestamp":1676653465803,"user_tz":-240,"elapsed":427,"user":{"displayName":"Pavel Astukov","userId":"16078133139068610731"}},"outputId":"ce477929-925a-4b7e-848a-f3e2e1712f44"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<matplotlib.axes._subplots.AxesSubplot at 0x7f81b0ec95e0>"]},"metadata":{},"execution_count":34},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}],"source":["sns.countplot(x='Survived', hue='Pclass', data=df)"]},{"cell_type":"code","execution_count":null,"id":"1e9e81cd","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":296},"id":"1e9e81cd","executionInfo":{"status":"ok","timestamp":1676651984715,"user_tz":-240,"elapsed":15,"user":{"displayName":"Pavel Astukov","userId":"16078133139068610731"}},"outputId":"248caa8c-f751-4817-a57b-f166f9844c51"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<matplotlib.axes._subplots.AxesSubplot at 0x7f81b1800550>"]},"metadata":{},"execution_count":13},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}],"source":["sns.countplot(x=\"Embarked\",hue='Survived', data=df)"]},{"cell_type":"code","source":["df.isna().sum().sort_values(ascending=False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NdXex3PRP0pU","executionInfo":{"status":"ok","timestamp":1676652036199,"user_tz":-240,"elapsed":11,"user":{"displayName":"Pavel Astukov","userId":"16078133139068610731"}},"outputId":"347d8cf3-b467-44cd-dbb8-e094d05dc0f7"},"id":"NdXex3PRP0pU","execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Cabin          687\n","Age            177\n","Embarked         2\n","PassengerId      0\n","Survived         0\n","Pclass           0\n","Name             0\n","Sex              0\n","SibSp            0\n","Parch            0\n","Ticket           0\n","Fare             0\n","dtype: int64"]},"metadata":{},"execution_count":16}]},{"cell_type":"code","execution_count":null,"id":"d37fb3fa","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":432},"id":"d37fb3fa","executionInfo":{"status":"ok","timestamp":1676651990099,"user_tz":-240,"elapsed":277,"user":{"displayName":"Pavel Astukov","userId":"16078133139068610731"}},"outputId":"95762a59-3bb9-4804-ede1-f4033bfb5f1b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Cabin          687\n","Age            177\n","Embarked         2\n","PassengerId      0\n","Survived         0\n","Pclass           0\n","Name             0\n","Sex              0\n","SibSp            0\n","Parch            0\n","Ticket           0\n","Fare             0\n","dtype: int64\n"]},{"output_type":"execute_result","data":{"text/plain":["             Total     %\n","Cabin          687  77.1\n","Age            177  19.9\n","Embarked         2   0.2\n","PassengerId      0   0.0\n","Survived         0   0.0"],"text/html":["\n","  <div id=\"df-2bf1445e-6da1-4375-8692-f8c21625b33a\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Total</th>\n","      <th>%</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>Cabin</th>\n","      <td>687</td>\n","      <td>77.1</td>\n","    </tr>\n","    <tr>\n","      <th>Age</th>\n","      <td>177</td>\n","      <td>19.9</td>\n","    </tr>\n","    <tr>\n","      <th>Embarked</th>\n","      <td>2</td>\n","      <td>0.2</td>\n","    </tr>\n","    <tr>\n","      <th>PassengerId</th>\n","      <td>0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>Survived</th>\n","      <td>0</td>\n","      <td>0.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2bf1445e-6da1-4375-8692-f8c21625b33a')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-2bf1445e-6da1-4375-8692-f8c21625b33a button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-2bf1445e-6da1-4375-8692-f8c21625b33a');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":14}],"source":["total = df.isnull().sum().sort_values(ascending=False)\n","print(total)\n","percent_1 = df.isnull().sum()/df.isnull().count()*100\n","percent_2 = (round(percent_1, 1)).sort_values(ascending=False)\n","missing_data = pd.concat([total, percent_2], axis=1, keys=['Total', '%'])\n","missing_data.head(5)"]},{"cell_type":"code","execution_count":null,"id":"d4c5a955","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d4c5a955","executionInfo":{"status":"ok","timestamp":1676652088908,"user_tz":-240,"elapsed":269,"user":{"displayName":"Pavel Astukov","userId":"16078133139068610731"}},"outputId":"029fde5a-5868-49fe-bc80-ea4f41b4d91c"},"outputs":[{"output_type":"stream","name":"stdout","text":["     Survived  Pclass  Sex        Age  SibSp  Parch     Fare  Embarked\n","0           0       3    0  22.000000      1      0   7.2500       0.0\n","1           1       1    1  38.000000      1      0  71.2833       1.0\n","2           1       3    1  26.000000      0      0   7.9250       0.0\n","3           1       1    1  35.000000      1      0  53.1000       0.0\n","4           0       3    0  35.000000      0      0   8.0500       0.0\n","..        ...     ...  ...        ...    ...    ...      ...       ...\n","886         0       2    0  27.000000      0      0  13.0000       0.0\n","887         1       1    1  19.000000      0      0  30.0000       0.0\n","888         0       3    1  29.699118      1      2  23.4500       0.0\n","889         1       1    0  26.000000      0      0  30.0000       1.0\n","890         0       3    0  32.000000      0      0   7.7500       2.0\n","\n","[891 rows x 8 columns]\n","Survived    0\n","Pclass      0\n","Sex         0\n","Age         0\n","SibSp       0\n","Parch       0\n","Fare        0\n","Embarked    0\n","dtype: int64\n"]}],"source":["def prepare_df(df):\n","    prepared_df = pd.DataFrame(df)\n","    prepared_df = prepared_df.drop(columns=['Name', 'Ticket', 'Cabin','PassengerId'])\n","    prepared_df['Embarked'].replace(['S', 'C', 'Q'], [0, 1, 2], inplace=True)\n","    prepared_df['Sex'].replace(['male', 'female'], [0, 1], inplace=True)\n","    prepared_df['Age'].fillna(prepared_df['Age'].mean(), inplace=True)\n","    prepared_df['Embarked'].fillna(np.round(prepared_df['Embarked'].mean()), inplace=True)\n","    return prepared_df\n","\n","processed_df = prepare_df(df)\n","print(processed_df)\n","print(processed_df.isna().sum())"]},{"cell_type":"code","execution_count":null,"id":"2ea9646a","metadata":{"id":"2ea9646a"},"outputs":[],"source":["X = processed_df[processed_df.columns.difference(['Survived'])]\n","y = processed_df['Survived']\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"]},{"cell_type":"code","execution_count":null,"id":"1c3912e4","metadata":{"id":"1c3912e4"},"outputs":[],"source":["from sklearn.neighbors import KNeighborsClassifier"]},{"cell_type":"code","execution_count":null,"id":"e6be49f2","metadata":{"id":"e6be49f2","executionInfo":{"status":"ok","timestamp":1676654986181,"user_tz":-240,"elapsed":324,"user":{"displayName":"Pavel Astukov","userId":"16078133139068610731"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"1b583aa4-c697-456e-f5d0-4e3395d79d61"},"outputs":[{"output_type":"stream","name":"stdout","text":["Help on class KNeighborsClassifier in module sklearn.neighbors._classification:\n","\n","class KNeighborsClassifier(sklearn.neighbors._base.KNeighborsMixin, sklearn.base.ClassifierMixin, sklearn.neighbors._base.NeighborsBase)\n"," |  KNeighborsClassifier(n_neighbors=5, *, weights='uniform', algorithm='auto', leaf_size=30, p=2, metric='minkowski', metric_params=None, n_jobs=None)\n"," |  \n"," |  Classifier implementing the k-nearest neighbors vote.\n"," |  \n"," |  Read more in the :ref:`User Guide <classification>`.\n"," |  \n"," |  Parameters\n"," |  ----------\n"," |  n_neighbors : int, default=5\n"," |      Number of neighbors to use by default for :meth:`kneighbors` queries.\n"," |  \n"," |  weights : {'uniform', 'distance'} or callable, default='uniform'\n"," |      Weight function used in prediction.  Possible values:\n"," |  \n"," |      - 'uniform' : uniform weights.  All points in each neighborhood\n"," |        are weighted equally.\n"," |      - 'distance' : weight points by the inverse of their distance.\n"," |        in this case, closer neighbors of a query point will have a\n"," |        greater influence than neighbors which are further away.\n"," |      - [callable] : a user-defined function which accepts an\n"," |        array of distances, and returns an array of the same shape\n"," |        containing the weights.\n"," |  \n"," |  algorithm : {'auto', 'ball_tree', 'kd_tree', 'brute'}, default='auto'\n"," |      Algorithm used to compute the nearest neighbors:\n"," |  \n"," |      - 'ball_tree' will use :class:`BallTree`\n"," |      - 'kd_tree' will use :class:`KDTree`\n"," |      - 'brute' will use a brute-force search.\n"," |      - 'auto' will attempt to decide the most appropriate algorithm\n"," |        based on the values passed to :meth:`fit` method.\n"," |  \n"," |      Note: fitting on sparse input will override the setting of\n"," |      this parameter, using brute force.\n"," |  \n"," |  leaf_size : int, default=30\n"," |      Leaf size passed to BallTree or KDTree.  This can affect the\n"," |      speed of the construction and query, as well as the memory\n"," |      required to store the tree.  The optimal value depends on the\n"," |      nature of the problem.\n"," |  \n"," |  p : int, default=2\n"," |      Power parameter for the Minkowski metric. When p = 1, this is\n"," |      equivalent to using manhattan_distance (l1), and euclidean_distance\n"," |      (l2) for p = 2. For arbitrary p, minkowski_distance (l_p) is used.\n"," |  \n"," |  metric : str or callable, default='minkowski'\n"," |      The distance metric to use for the tree.  The default metric is\n"," |      minkowski, and with p=2 is equivalent to the standard Euclidean\n"," |      metric. For a list of available metrics, see the documentation of\n"," |      :class:`~sklearn.metrics.DistanceMetric`.\n"," |      If metric is \"precomputed\", X is assumed to be a distance matrix and\n"," |      must be square during fit. X may be a :term:`sparse graph`,\n"," |      in which case only \"nonzero\" elements may be considered neighbors.\n"," |  \n"," |  metric_params : dict, default=None\n"," |      Additional keyword arguments for the metric function.\n"," |  \n"," |  n_jobs : int, default=None\n"," |      The number of parallel jobs to run for neighbors search.\n"," |      ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n"," |      ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n"," |      for more details.\n"," |      Doesn't affect :meth:`fit` method.\n"," |  \n"," |  Attributes\n"," |  ----------\n"," |  classes_ : array of shape (n_classes,)\n"," |      Class labels known to the classifier\n"," |  \n"," |  effective_metric_ : str or callble\n"," |      The distance metric used. It will be same as the `metric` parameter\n"," |      or a synonym of it, e.g. 'euclidean' if the `metric` parameter set to\n"," |      'minkowski' and `p` parameter set to 2.\n"," |  \n"," |  effective_metric_params_ : dict\n"," |      Additional keyword arguments for the metric function. For most metrics\n"," |      will be same with `metric_params` parameter, but may also contain the\n"," |      `p` parameter value if the `effective_metric_` attribute is set to\n"," |      'minkowski'.\n"," |  \n"," |  n_features_in_ : int\n"," |      Number of features seen during :term:`fit`.\n"," |  \n"," |      .. versionadded:: 0.24\n"," |  \n"," |  feature_names_in_ : ndarray of shape (`n_features_in_`,)\n"," |      Names of features seen during :term:`fit`. Defined only when `X`\n"," |      has feature names that are all strings.\n"," |  \n"," |      .. versionadded:: 1.0\n"," |  \n"," |  n_samples_fit_ : int\n"," |      Number of samples in the fitted data.\n"," |  \n"," |  outputs_2d_ : bool\n"," |      False when `y`'s shape is (n_samples, ) or (n_samples, 1) during fit\n"," |      otherwise True.\n"," |  \n"," |  See Also\n"," |  --------\n"," |  RadiusNeighborsClassifier: Classifier based on neighbors within a fixed radius.\n"," |  KNeighborsRegressor: Regression based on k-nearest neighbors.\n"," |  RadiusNeighborsRegressor: Regression based on neighbors within a fixed radius.\n"," |  NearestNeighbors: Unsupervised learner for implementing neighbor searches.\n"," |  \n"," |  Notes\n"," |  -----\n"," |  See :ref:`Nearest Neighbors <neighbors>` in the online documentation\n"," |  for a discussion of the choice of ``algorithm`` and ``leaf_size``.\n"," |  \n"," |  .. warning::\n"," |  \n"," |     Regarding the Nearest Neighbors algorithms, if it is found that two\n"," |     neighbors, neighbor `k+1` and `k`, have identical distances\n"," |     but different labels, the results will depend on the ordering of the\n"," |     training data.\n"," |  \n"," |  https://en.wikipedia.org/wiki/K-nearest_neighbor_algorithm\n"," |  \n"," |  Examples\n"," |  --------\n"," |  >>> X = [[0], [1], [2], [3]]\n"," |  >>> y = [0, 0, 1, 1]\n"," |  >>> from sklearn.neighbors import KNeighborsClassifier\n"," |  >>> neigh = KNeighborsClassifier(n_neighbors=3)\n"," |  >>> neigh.fit(X, y)\n"," |  KNeighborsClassifier(...)\n"," |  >>> print(neigh.predict([[1.1]]))\n"," |  [0]\n"," |  >>> print(neigh.predict_proba([[0.9]]))\n"," |  [[0.666... 0.333...]]\n"," |  \n"," |  Method resolution order:\n"," |      KNeighborsClassifier\n"," |      sklearn.neighbors._base.KNeighborsMixin\n"," |      sklearn.base.ClassifierMixin\n"," |      sklearn.neighbors._base.NeighborsBase\n"," |      sklearn.base.MultiOutputMixin\n"," |      sklearn.base.BaseEstimator\n"," |      builtins.object\n"," |  \n"," |  Methods defined here:\n"," |  \n"," |  __init__(self, n_neighbors=5, *, weights='uniform', algorithm='auto', leaf_size=30, p=2, metric='minkowski', metric_params=None, n_jobs=None)\n"," |      Initialize self.  See help(type(self)) for accurate signature.\n"," |  \n"," |  fit(self, X, y)\n"," |      Fit the k-nearest neighbors classifier from the training dataset.\n"," |      \n"," |      Parameters\n"," |      ----------\n"," |      X : {array-like, sparse matrix} of shape (n_samples, n_features) or                 (n_samples, n_samples) if metric='precomputed'\n"," |          Training data.\n"," |      \n"," |      y : {array-like, sparse matrix} of shape (n_samples,) or                 (n_samples, n_outputs)\n"," |          Target values.\n"," |      \n"," |      Returns\n"," |      -------\n"," |      self : KNeighborsClassifier\n"," |          The fitted k-nearest neighbors classifier.\n"," |  \n"," |  predict(self, X)\n"," |      Predict the class labels for the provided data.\n"," |      \n"," |      Parameters\n"," |      ----------\n"," |      X : array-like of shape (n_queries, n_features),                 or (n_queries, n_indexed) if metric == 'precomputed'\n"," |          Test samples.\n"," |      \n"," |      Returns\n"," |      -------\n"," |      y : ndarray of shape (n_queries,) or (n_queries, n_outputs)\n"," |          Class labels for each data sample.\n"," |  \n"," |  predict_proba(self, X)\n"," |      Return probability estimates for the test data X.\n"," |      \n"," |      Parameters\n"," |      ----------\n"," |      X : array-like of shape (n_queries, n_features),                 or (n_queries, n_indexed) if metric == 'precomputed'\n"," |          Test samples.\n"," |      \n"," |      Returns\n"," |      -------\n"," |      p : ndarray of shape (n_queries, n_classes), or a list of n_outputs                 of such arrays if n_outputs > 1.\n"," |          The class probabilities of the input samples. Classes are ordered\n"," |          by lexicographic order.\n"," |  \n"," |  ----------------------------------------------------------------------\n"," |  Data and other attributes defined here:\n"," |  \n"," |  __abstractmethods__ = frozenset()\n"," |  \n"," |  ----------------------------------------------------------------------\n"," |  Methods inherited from sklearn.neighbors._base.KNeighborsMixin:\n"," |  \n"," |  kneighbors(self, X=None, n_neighbors=None, return_distance=True)\n"," |      Find the K-neighbors of a point.\n"," |      \n"," |      Returns indices of and distances to the neighbors of each point.\n"," |      \n"," |      Parameters\n"," |      ----------\n"," |      X : array-like, shape (n_queries, n_features),             or (n_queries, n_indexed) if metric == 'precomputed',                 default=None\n"," |          The query point or points.\n"," |          If not provided, neighbors of each indexed point are returned.\n"," |          In this case, the query point is not considered its own neighbor.\n"," |      \n"," |      n_neighbors : int, default=None\n"," |          Number of neighbors required for each sample. The default is the\n"," |          value passed to the constructor.\n"," |      \n"," |      return_distance : bool, default=True\n"," |          Whether or not to return the distances.\n"," |      \n"," |      Returns\n"," |      -------\n"," |      neigh_dist : ndarray of shape (n_queries, n_neighbors)\n"," |          Array representing the lengths to points, only present if\n"," |          return_distance=True.\n"," |      \n"," |      neigh_ind : ndarray of shape (n_queries, n_neighbors)\n"," |          Indices of the nearest points in the population matrix.\n"," |      \n"," |      Examples\n"," |      --------\n"," |      In the following example, we construct a NearestNeighbors\n"," |      class from an array representing our data set and ask who's\n"," |      the closest point to [1,1,1]\n"," |      \n"," |      >>> samples = [[0., 0., 0.], [0., .5, 0.], [1., 1., .5]]\n"," |      >>> from sklearn.neighbors import NearestNeighbors\n"," |      >>> neigh = NearestNeighbors(n_neighbors=1)\n"," |      >>> neigh.fit(samples)\n"," |      NearestNeighbors(n_neighbors=1)\n"," |      >>> print(neigh.kneighbors([[1., 1., 1.]]))\n"," |      (array([[0.5]]), array([[2]]))\n"," |      \n"," |      As you can see, it returns [[0.5]], and [[2]], which means that the\n"," |      element is at distance 0.5 and is the third element of samples\n"," |      (indexes start at 0). You can also query for multiple points:\n"," |      \n"," |      >>> X = [[0., 1., 0.], [1., 0., 1.]]\n"," |      >>> neigh.kneighbors(X, return_distance=False)\n"," |      array([[1],\n"," |             [2]]...)\n"," |  \n"," |  kneighbors_graph(self, X=None, n_neighbors=None, mode='connectivity')\n"," |      Compute the (weighted) graph of k-Neighbors for points in X.\n"," |      \n"," |      Parameters\n"," |      ----------\n"," |      X : array-like of shape (n_queries, n_features),                 or (n_queries, n_indexed) if metric == 'precomputed',                 default=None\n"," |          The query point or points.\n"," |          If not provided, neighbors of each indexed point are returned.\n"," |          In this case, the query point is not considered its own neighbor.\n"," |          For ``metric='precomputed'`` the shape should be\n"," |          (n_queries, n_indexed). Otherwise the shape should be\n"," |          (n_queries, n_features).\n"," |      \n"," |      n_neighbors : int, default=None\n"," |          Number of neighbors for each sample. The default is the value\n"," |          passed to the constructor.\n"," |      \n"," |      mode : {'connectivity', 'distance'}, default='connectivity'\n"," |          Type of returned matrix: 'connectivity' will return the\n"," |          connectivity matrix with ones and zeros, in 'distance' the\n"," |          edges are distances between points, type of distance\n"," |          depends on the selected metric parameter in\n"," |          NearestNeighbors class.\n"," |      \n"," |      Returns\n"," |      -------\n"," |      A : sparse-matrix of shape (n_queries, n_samples_fit)\n"," |          `n_samples_fit` is the number of samples in the fitted data.\n"," |          `A[i, j]` gives the weight of the edge connecting `i` to `j`.\n"," |          The matrix is of CSR format.\n"," |      \n"," |      See Also\n"," |      --------\n"," |      NearestNeighbors.radius_neighbors_graph : Compute the (weighted) graph\n"," |          of Neighbors for points in X.\n"," |      \n"," |      Examples\n"," |      --------\n"," |      >>> X = [[0], [3], [1]]\n"," |      >>> from sklearn.neighbors import NearestNeighbors\n"," |      >>> neigh = NearestNeighbors(n_neighbors=2)\n"," |      >>> neigh.fit(X)\n"," |      NearestNeighbors(n_neighbors=2)\n"," |      >>> A = neigh.kneighbors_graph(X)\n"," |      >>> A.toarray()\n"," |      array([[1., 0., 1.],\n"," |             [0., 1., 1.],\n"," |             [1., 0., 1.]])\n"," |  \n"," |  ----------------------------------------------------------------------\n"," |  Data descriptors inherited from sklearn.neighbors._base.KNeighborsMixin:\n"," |  \n"," |  __dict__\n"," |      dictionary for instance variables (if defined)\n"," |  \n"," |  __weakref__\n"," |      list of weak references to the object (if defined)\n"," |  \n"," |  ----------------------------------------------------------------------\n"," |  Methods inherited from sklearn.base.ClassifierMixin:\n"," |  \n"," |  score(self, X, y, sample_weight=None)\n"," |      Return the mean accuracy on the given test data and labels.\n"," |      \n"," |      In multi-label classification, this is the subset accuracy\n"," |      which is a harsh metric since you require for each sample that\n"," |      each label set be correctly predicted.\n"," |      \n"," |      Parameters\n"," |      ----------\n"," |      X : array-like of shape (n_samples, n_features)\n"," |          Test samples.\n"," |      \n"," |      y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n"," |          True labels for `X`.\n"," |      \n"," |      sample_weight : array-like of shape (n_samples,), default=None\n"," |          Sample weights.\n"," |      \n"," |      Returns\n"," |      -------\n"," |      score : float\n"," |          Mean accuracy of ``self.predict(X)`` wrt. `y`.\n"," |  \n"," |  ----------------------------------------------------------------------\n"," |  Methods inherited from sklearn.base.BaseEstimator:\n"," |  \n"," |  __getstate__(self)\n"," |  \n"," |  __repr__(self, N_CHAR_MAX=700)\n"," |      Return repr(self).\n"," |  \n"," |  __setstate__(self, state)\n"," |  \n"," |  get_params(self, deep=True)\n"," |      Get parameters for this estimator.\n"," |      \n"," |      Parameters\n"," |      ----------\n"," |      deep : bool, default=True\n"," |          If True, will return the parameters for this estimator and\n"," |          contained subobjects that are estimators.\n"," |      \n"," |      Returns\n"," |      -------\n"," |      params : dict\n"," |          Parameter names mapped to their values.\n"," |  \n"," |  set_params(self, **params)\n"," |      Set the parameters of this estimator.\n"," |      \n"," |      The method works on simple estimators as well as on nested objects\n"," |      (such as :class:`~sklearn.pipeline.Pipeline`). The latter have\n"," |      parameters of the form ``<component>__<parameter>`` so that it's\n"," |      possible to update each component of a nested object.\n"," |      \n"," |      Parameters\n"," |      ----------\n"," |      **params : dict\n"," |          Estimator parameters.\n"," |      \n"," |      Returns\n"," |      -------\n"," |      self : estimator instance\n"," |          Estimator instance.\n","\n"]}],"source":["import sklearn\n","help(sklearn.neighbors.KNeighborsClassifier)"]},{"cell_type":"code","execution_count":null,"id":"c94e39cb","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c94e39cb","executionInfo":{"status":"ok","timestamp":1676652438933,"user_tz":-240,"elapsed":8,"user":{"displayName":"Pavel Astukov","userId":"16078133139068610731"}},"outputId":"5e48b4da-9b03-4700-dc0a-17b3748bd76a"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["KNeighborsClassifier(n_neighbors=3)"]},"metadata":{},"execution_count":23}],"source":["model = KNeighborsClassifier(n_neighbors=3)\n","model.fit(X.values, y.values)"]},{"cell_type":"code","execution_count":null,"id":"a547d009","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a547d009","executionInfo":{"status":"ok","timestamp":1676652444693,"user_tz":-240,"elapsed":315,"user":{"displayName":"Pavel Astukov","userId":"16078133139068610731"}},"outputId":"d719d5f4-53e4-4a2c-d889-6d9c4a35d487"},"outputs":[{"output_type":"stream","name":"stdout","text":["accuracy is  0.8491620111731844\n","TP  45\n","FP  11\n","FN  16\n","TN  107\n"]}],"source":["answers = []\n","TP, FP, FN, TN = 0, 0, 0, 0\n","\n","for inputs, answer in zip(X_test.values, y_test.values):\n","    model_answer = model.predict(np.array(inputs, ndmin=2))\n","    if model_answer == answer:\n","        answers.append(1)\n","    else:\n","        answers.append(0)\n","    \n","    if model_answer == answer == 1:\n","        TP += 1\n","    elif model_answer == answer == 0:\n","        TN += 1\n","    elif model_answer != answer and model_answer == 1:\n","        FP += 1\n","    elif model_answer != answer and model_answer == 0:\n","        FN += 1\n","print('accuracy is ', sum(answers)/len(answers))\n","print('TP ', (TP))\n","print('FP ', (FP))\n","print('FN ', (FN))\n","print('TN ', (TN))"]},{"cell_type":"code","source":["tpr = TP/(TP + FP)\n","fpr = FP/(FP + TN)\n","y_pred = model.predict(X_test) \n","from sklearn.metrics import roc_curve\n","FPR, TPR, threshold = roc_curve(y_test, y_pred)\n","\n","fig, axs = plt.subplots(1)\n","axs.plot(FPR, TPR)\n","\n","print(FPR, TPR)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":317},"id":"-aJJ5Hd3Vcev","executionInfo":{"status":"ok","timestamp":1676656948571,"user_tz":-240,"elapsed":1490,"user":{"displayName":"Pavel Astukov","userId":"16078133139068610731"}},"outputId":"bcd51aec-d079-4c1f-847a-7b65949cc12a"},"id":"-aJJ5Hd3Vcev","execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/sklearn/base.py:443: UserWarning: X has feature names, but KNeighborsClassifier was fitted without feature names\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["[0.         0.09322034 1.        ] [0.         0.73770492 1.        ]\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","execution_count":null,"id":"8f35594a","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8f35594a","executionInfo":{"status":"ok","timestamp":1676652454321,"user_tz":-240,"elapsed":424,"user":{"displayName":"Pavel Astukov","userId":"16078133139068610731"}},"outputId":"88533c30-a0b2-4170-a514-58521c685ae6"},"outputs":[{"output_type":"stream","name":"stdout","text":["[[107  11]\n"," [ 16  45]]\n","[[ 45  11]\n"," [ 16 107]]\n","tp  45\n","fp  11\n","fn  16\n","tn  107\n"]}],"source":["from sklearn.metrics import confusion_matrix\n","\n","y_pred = model.predict(np.array(X_test, ndmin=2))\n","conf_matr = confusion_matrix(y_test, y_pred)\n","print(conf_matr)\n","print(np.flip(conf_matr).T)\n","tn, fp, fn, tp = conf_matr.ravel()\n","print('tp ', tp)\n","print('fp ', fp)\n","print('fn ', fn)\n","print('tn ', tn)"]},{"cell_type":"code","execution_count":null,"id":"ee1049d4","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ee1049d4","executionInfo":{"status":"ok","timestamp":1676652475312,"user_tz":-240,"elapsed":314,"user":{"displayName":"Pavel Astukov","userId":"16078133139068610731"}},"outputId":"70e7973f-3589-4720-b365-e5e32739c743"},"outputs":[{"output_type":"stream","name":"stdout","text":["precision is 0.8035714285714286\n","recall is  0.7377049180327869\n","accuracy is 0.8491620111731844\n"]}],"source":["precision = TP/ (TP + FP)\n","print('precision is', precision)\n","\n","recall = TP / (TP + FN)\n","print('recall is ', recall)\n","\n","accuracy = (TP + TN) / (TP + TN + FP + FN)\n","print('accuracy is', accuracy)"]},{"cell_type":"code","execution_count":null,"id":"87d48b8d","metadata":{"id":"87d48b8d"},"outputs":[],"source":["from sklearn.linear_model import SGDClassifier"]},{"cell_type":"code","execution_count":null,"id":"da40ede3","metadata":{"id":"da40ede3","outputId":"9648b96a-a338-4874-b55b-eaed0f0862b0"},"outputs":[{"name":"stdout","output_type":"stream","text":["Help on class SGDClassifier in module sklearn.linear_model._stochastic_gradient:\n","\n","class SGDClassifier(BaseSGDClassifier)\n"," |  SGDClassifier(loss='hinge', *, penalty='l2', alpha=0.0001, l1_ratio=0.15, fit_intercept=True, max_iter=1000, tol=0.001, shuffle=True, verbose=0, epsilon=0.1, n_jobs=None, random_state=None, learning_rate='optimal', eta0=0.0, power_t=0.5, early_stopping=False, validation_fraction=0.1, n_iter_no_change=5, class_weight=None, warm_start=False, average=False)\n"," |  \n"," |  Linear classifiers (SVM, logistic regression, etc.) with SGD training.\n"," |  \n"," |  This estimator implements regularized linear models with stochastic\n"," |  gradient descent (SGD) learning: the gradient of the loss is estimated\n"," |  each sample at a time and the model is updated along the way with a\n"," |  decreasing strength schedule (aka learning rate). SGD allows minibatch\n"," |  (online/out-of-core) learning via the `partial_fit` method.\n"," |  For best results using the default learning rate schedule, the data should\n"," |  have zero mean and unit variance.\n"," |  \n"," |  This implementation works with data represented as dense or sparse arrays\n"," |  of floating point values for the features. The model it fits can be\n"," |  controlled with the loss parameter; by default, it fits a linear support\n"," |  vector machine (SVM).\n"," |  \n"," |  The regularizer is a penalty added to the loss function that shrinks model\n"," |  parameters towards the zero vector using either the squared euclidean norm\n"," |  L2 or the absolute norm L1 or a combination of both (Elastic Net). If the\n"," |  parameter update crosses the 0.0 value because of the regularizer, the\n"," |  update is truncated to 0.0 to allow for learning sparse models and achieve\n"," |  online feature selection.\n"," |  \n"," |  Read more in the :ref:`User Guide <sgd>`.\n"," |  \n"," |  Parameters\n"," |  ----------\n"," |  loss : str, default='hinge'\n"," |      The loss function to be used. Defaults to 'hinge', which gives a\n"," |      linear SVM.\n"," |  \n"," |      The possible options are 'hinge', 'log', 'modified_huber',\n"," |      'squared_hinge', 'perceptron', or a regression loss: 'squared_error',\n"," |      'huber', 'epsilon_insensitive', or 'squared_epsilon_insensitive'.\n"," |  \n"," |      The 'log' loss gives logistic regression, a probabilistic classifier.\n"," |      'modified_huber' is another smooth loss that brings tolerance to\n"," |      outliers as well as probability estimates.\n"," |      'squared_hinge' is like hinge but is quadratically penalized.\n"," |      'perceptron' is the linear loss used by the perceptron algorithm.\n"," |      The other losses are designed for regression but can be useful in\n"," |      classification as well; see\n"," |      :class:`~sklearn.linear_model.SGDRegressor` for a description.\n"," |  \n"," |      More details about the losses formulas can be found in the\n"," |      :ref:`User Guide <sgd_mathematical_formulation>`.\n"," |  \n"," |      .. deprecated:: 1.0\n"," |          The loss 'squared_loss' was deprecated in v1.0 and will be removed\n"," |          in version 1.2. Use `loss='squared_error'` which is equivalent.\n"," |  \n"," |  penalty : {'l2', 'l1', 'elasticnet'}, default='l2'\n"," |      The penalty (aka regularization term) to be used. Defaults to 'l2'\n"," |      which is the standard regularizer for linear SVM models. 'l1' and\n"," |      'elasticnet' might bring sparsity to the model (feature selection)\n"," |      not achievable with 'l2'.\n"," |  \n"," |  alpha : float, default=0.0001\n"," |      Constant that multiplies the regularization term. The higher the\n"," |      value, the stronger the regularization.\n"," |      Also used to compute the learning rate when set to `learning_rate` is\n"," |      set to 'optimal'.\n"," |  \n"," |  l1_ratio : float, default=0.15\n"," |      The Elastic Net mixing parameter, with 0 <= l1_ratio <= 1.\n"," |      l1_ratio=0 corresponds to L2 penalty, l1_ratio=1 to L1.\n"," |      Only used if `penalty` is 'elasticnet'.\n"," |  \n"," |  fit_intercept : bool, default=True\n"," |      Whether the intercept should be estimated or not. If False, the\n"," |      data is assumed to be already centered.\n"," |  \n"," |  max_iter : int, default=1000\n"," |      The maximum number of passes over the training data (aka epochs).\n"," |      It only impacts the behavior in the ``fit`` method, and not the\n"," |      :meth:`partial_fit` method.\n"," |  \n"," |      .. versionadded:: 0.19\n"," |  \n"," |  tol : float, default=1e-3\n"," |      The stopping criterion. If it is not None, training will stop\n"," |      when (loss > best_loss - tol) for ``n_iter_no_change`` consecutive\n"," |      epochs.\n"," |      Convergence is checked against the training loss or the\n"," |      validation loss depending on the `early_stopping` parameter.\n"," |  \n"," |      .. versionadded:: 0.19\n"," |  \n"," |  shuffle : bool, default=True\n"," |      Whether or not the training data should be shuffled after each epoch.\n"," |  \n"," |  verbose : int, default=0\n"," |      The verbosity level.\n"," |  \n"," |  epsilon : float, default=0.1\n"," |      Epsilon in the epsilon-insensitive loss functions; only if `loss` is\n"," |      'huber', 'epsilon_insensitive', or 'squared_epsilon_insensitive'.\n"," |      For 'huber', determines the threshold at which it becomes less\n"," |      important to get the prediction exactly right.\n"," |      For epsilon-insensitive, any differences between the current prediction\n"," |      and the correct label are ignored if they are less than this threshold.\n"," |  \n"," |  n_jobs : int, default=None\n"," |      The number of CPUs to use to do the OVA (One Versus All, for\n"," |      multi-class problems) computation.\n"," |      ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n"," |      ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n"," |      for more details.\n"," |  \n"," |  random_state : int, RandomState instance, default=None\n"," |      Used for shuffling the data, when ``shuffle`` is set to ``True``.\n"," |      Pass an int for reproducible output across multiple function calls.\n"," |      See :term:`Glossary <random_state>`.\n"," |  \n"," |  learning_rate : str, default='optimal'\n"," |      The learning rate schedule:\n"," |  \n"," |      - 'constant': `eta = eta0`\n"," |      - 'optimal': `eta = 1.0 / (alpha * (t + t0))`\n"," |        where t0 is chosen by a heuristic proposed by Leon Bottou.\n"," |      - 'invscaling': `eta = eta0 / pow(t, power_t)`\n"," |      - 'adaptive': eta = eta0, as long as the training keeps decreasing.\n"," |        Each time n_iter_no_change consecutive epochs fail to decrease the\n"," |        training loss by tol or fail to increase validation score by tol if\n"," |        early_stopping is True, the current learning rate is divided by 5.\n"," |  \n"," |          .. versionadded:: 0.20\n"," |              Added 'adaptive' option\n"," |  \n"," |  eta0 : float, default=0.0\n"," |      The initial learning rate for the 'constant', 'invscaling' or\n"," |      'adaptive' schedules. The default value is 0.0 as eta0 is not used by\n"," |      the default schedule 'optimal'.\n"," |  \n"," |  power_t : float, default=0.5\n"," |      The exponent for inverse scaling learning rate [default 0.5].\n"," |  \n"," |  early_stopping : bool, default=False\n"," |      Whether to use early stopping to terminate training when validation\n"," |      score is not improving. If set to True, it will automatically set aside\n"," |      a stratified fraction of training data as validation and terminate\n"," |      training when validation score returned by the `score` method is not\n"," |      improving by at least tol for n_iter_no_change consecutive epochs.\n"," |  \n"," |      .. versionadded:: 0.20\n"," |          Added 'early_stopping' option\n"," |  \n"," |  validation_fraction : float, default=0.1\n"," |      The proportion of training data to set aside as validation set for\n"," |      early stopping. Must be between 0 and 1.\n"," |      Only used if `early_stopping` is True.\n"," |  \n"," |      .. versionadded:: 0.20\n"," |          Added 'validation_fraction' option\n"," |  \n"," |  n_iter_no_change : int, default=5\n"," |      Number of iterations with no improvement to wait before stopping\n"," |      fitting.\n"," |      Convergence is checked against the training loss or the\n"," |      validation loss depending on the `early_stopping` parameter.\n"," |  \n"," |      .. versionadded:: 0.20\n"," |          Added 'n_iter_no_change' option\n"," |  \n"," |  class_weight : dict, {class_label: weight} or \"balanced\", default=None\n"," |      Preset for the class_weight fit parameter.\n"," |  \n"," |      Weights associated with classes. If not given, all classes\n"," |      are supposed to have weight one.\n"," |  \n"," |      The \"balanced\" mode uses the values of y to automatically adjust\n"," |      weights inversely proportional to class frequencies in the input data\n"," |      as ``n_samples / (n_classes * np.bincount(y))``.\n"," |  \n"," |  warm_start : bool, default=False\n"," |      When set to True, reuse the solution of the previous call to fit as\n"," |      initialization, otherwise, just erase the previous solution.\n"," |      See :term:`the Glossary <warm_start>`.\n"," |  \n"," |      Repeatedly calling fit or partial_fit when warm_start is True can\n"," |      result in a different solution than when calling fit a single time\n"," |      because of the way the data is shuffled.\n"," |      If a dynamic learning rate is used, the learning rate is adapted\n"," |      depending on the number of samples already seen. Calling ``fit`` resets\n"," |      this counter, while ``partial_fit`` will result in increasing the\n"," |      existing counter.\n"," |  \n"," |  average : bool or int, default=False\n"," |      When set to True, computes the averaged SGD weights across all\n"," |      updates and stores the result in the ``coef_`` attribute. If set to\n"," |      an int greater than 1, averaging will begin once the total number of\n"," |      samples seen reaches `average`. So ``average=10`` will begin\n"," |      averaging after seeing 10 samples.\n"," |  \n"," |  Attributes\n"," |  ----------\n"," |  coef_ : ndarray of shape (1, n_features) if n_classes == 2 else             (n_classes, n_features)\n"," |      Weights assigned to the features.\n"," |  \n"," |  intercept_ : ndarray of shape (1,) if n_classes == 2 else (n_classes,)\n"," |      Constants in decision function.\n"," |  \n"," |  n_iter_ : int\n"," |      The actual number of iterations before reaching the stopping criterion.\n"," |      For multiclass fits, it is the maximum over every binary fit.\n"," |  \n"," |  loss_function_ : concrete ``LossFunction``\n"," |  \n"," |  classes_ : array of shape (n_classes,)\n"," |  \n"," |  t_ : int\n"," |      Number of weight updates performed during training.\n"," |      Same as ``(n_iter_ * n_samples)``.\n"," |  \n"," |  n_features_in_ : int\n"," |      Number of features seen during :term:`fit`.\n"," |  \n"," |      .. versionadded:: 0.24\n"," |  \n"," |  feature_names_in_ : ndarray of shape (`n_features_in_`,)\n"," |      Names of features seen during :term:`fit`. Defined only when `X`\n"," |      has feature names that are all strings.\n"," |  \n"," |      .. versionadded:: 1.0\n"," |  \n"," |  See Also\n"," |  --------\n"," |  sklearn.svm.LinearSVC : Linear support vector classification.\n"," |  LogisticRegression : Logistic regression.\n"," |  Perceptron : Inherits from SGDClassifier. ``Perceptron()`` is equivalent to\n"," |      ``SGDClassifier(loss=\"perceptron\", eta0=1, learning_rate=\"constant\",\n"," |      penalty=None)``.\n"," |  \n"," |  Examples\n"," |  --------\n"," |  >>> import numpy as np\n"," |  >>> from sklearn.linear_model import SGDClassifier\n"," |  >>> from sklearn.preprocessing import StandardScaler\n"," |  >>> from sklearn.pipeline import make_pipeline\n"," |  >>> X = np.array([[-1, -1], [-2, -1], [1, 1], [2, 1]])\n"," |  >>> Y = np.array([1, 1, 2, 2])\n"," |  >>> # Always scale the input. The most convenient way is to use a pipeline.\n"," |  >>> clf = make_pipeline(StandardScaler(),\n"," |  ...                     SGDClassifier(max_iter=1000, tol=1e-3))\n"," |  >>> clf.fit(X, Y)\n"," |  Pipeline(steps=[('standardscaler', StandardScaler()),\n"," |                  ('sgdclassifier', SGDClassifier())])\n"," |  >>> print(clf.predict([[-0.8, -1]]))\n"," |  [1]\n"," |  \n"," |  Method resolution order:\n"," |      SGDClassifier\n"," |      BaseSGDClassifier\n"," |      sklearn.linear_model._base.LinearClassifierMixin\n"," |      sklearn.base.ClassifierMixin\n"," |      BaseSGD\n"," |      sklearn.linear_model._base.SparseCoefMixin\n"," |      sklearn.base.BaseEstimator\n"," |      builtins.object\n"," |  \n"," |  Methods defined here:\n"," |  \n"," |  __init__(self, loss='hinge', *, penalty='l2', alpha=0.0001, l1_ratio=0.15, fit_intercept=True, max_iter=1000, tol=0.001, shuffle=True, verbose=0, epsilon=0.1, n_jobs=None, random_state=None, learning_rate='optimal', eta0=0.0, power_t=0.5, early_stopping=False, validation_fraction=0.1, n_iter_no_change=5, class_weight=None, warm_start=False, average=False)\n"," |      Initialize self.  See help(type(self)) for accurate signature.\n"," |  \n"," |  predict_log_proba(self, X)\n"," |      Log of probability estimates.\n"," |      \n"," |      This method is only available for log loss and modified Huber loss.\n"," |      \n"," |      When loss=\"modified_huber\", probability estimates may be hard zeros\n"," |      and ones, so taking the logarithm is not possible.\n"," |      \n"," |      See ``predict_proba`` for details.\n"," |      \n"," |      Parameters\n"," |      ----------\n"," |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n"," |          Input data for prediction.\n"," |      \n"," |      Returns\n"," |      -------\n"," |      T : array-like, shape (n_samples, n_classes)\n"," |          Returns the log-probability of the sample for each class in the\n"," |          model, where classes are ordered as they are in\n"," |          `self.classes_`.\n"," |  \n"," |  predict_proba(self, X)\n"," |      Probability estimates.\n"," |      \n"," |      This method is only available for log loss and modified Huber loss.\n"," |      \n"," |      Multiclass probability estimates are derived from binary (one-vs.-rest)\n"," |      estimates by simple normalization, as recommended by Zadrozny and\n"," |      Elkan.\n"," |      \n"," |      Binary probability estimates for loss=\"modified_huber\" are given by\n"," |      (clip(decision_function(X), -1, 1) + 1) / 2. For other loss functions\n"," |      it is necessary to perform proper probability calibration by wrapping\n"," |      the classifier with\n"," |      :class:`~sklearn.calibration.CalibratedClassifierCV` instead.\n"," |      \n"," |      Parameters\n"," |      ----------\n"," |      X : {array-like, sparse matrix}, shape (n_samples, n_features)\n"," |          Input data for prediction.\n"," |      \n"," |      Returns\n"," |      -------\n"," |      ndarray of shape (n_samples, n_classes)\n"," |          Returns the probability of the sample for each class in the model,\n"," |          where classes are ordered as they are in `self.classes_`.\n"," |      \n"," |      References\n"," |      ----------\n"," |      Zadrozny and Elkan, \"Transforming classifier scores into multiclass\n"," |      probability estimates\", SIGKDD'02,\n"," |      https://dl.acm.org/doi/pdf/10.1145/775047.775151\n"," |      \n"," |      The justification for the formula in the loss=\"modified_huber\"\n"," |      case is in the appendix B in:\n"," |      http://jmlr.csail.mit.edu/papers/volume2/zhang02c/zhang02c.pdf\n"," |  \n"," |  ----------------------------------------------------------------------\n"," |  Data and other attributes defined here:\n"," |  \n"," |  __abstractmethods__ = frozenset()\n"," |  \n"," |  ----------------------------------------------------------------------\n"," |  Methods inherited from BaseSGDClassifier:\n"," |  \n"," |  fit(self, X, y, coef_init=None, intercept_init=None, sample_weight=None)\n"," |      Fit linear model with Stochastic Gradient Descent.\n"," |      \n"," |      Parameters\n"," |      ----------\n"," |      X : {array-like, sparse matrix}, shape (n_samples, n_features)\n"," |          Training data.\n"," |      \n"," |      y : ndarray of shape (n_samples,)\n"," |          Target values.\n"," |      \n"," |      coef_init : ndarray of shape (n_classes, n_features), default=None\n"," |          The initial coefficients to warm-start the optimization.\n"," |      \n"," |      intercept_init : ndarray of shape (n_classes,), default=None\n"," |          The initial intercept to warm-start the optimization.\n"," |      \n"," |      sample_weight : array-like, shape (n_samples,), default=None\n"," |          Weights applied to individual samples.\n"," |          If not provided, uniform weights are assumed. These weights will\n"," |          be multiplied with class_weight (passed through the\n"," |          constructor) if class_weight is specified.\n"," |      \n"," |      Returns\n"," |      -------\n"," |      self : object\n"," |          Returns an instance of self.\n"," |  \n"," |  partial_fit(self, X, y, classes=None, sample_weight=None)\n"," |      Perform one epoch of stochastic gradient descent on given samples.\n"," |      \n"," |      Internally, this method uses ``max_iter = 1``. Therefore, it is not\n"," |      guaranteed that a minimum of the cost function is reached after calling\n"," |      it once. Matters such as objective convergence, early stopping, and\n"," |      learning rate adjustments should be handled by the user.\n"," |      \n"," |      Parameters\n"," |      ----------\n"," |      X : {array-like, sparse matrix}, shape (n_samples, n_features)\n"," |          Subset of the training data.\n"," |      \n"," |      y : ndarray of shape (n_samples,)\n"," |          Subset of the target values.\n"," |      \n"," |      classes : ndarray of shape (n_classes,), default=None\n"," |          Classes across all calls to partial_fit.\n"," |          Can be obtained by via `np.unique(y_all)`, where y_all is the\n"," |          target vector of the entire dataset.\n"," |          This argument is required for the first call to partial_fit\n"," |          and can be omitted in the subsequent calls.\n"," |          Note that y doesn't need to contain all labels in `classes`.\n"," |      \n"," |      sample_weight : array-like, shape (n_samples,), default=None\n"," |          Weights applied to individual samples.\n"," |          If not provided, uniform weights are assumed.\n"," |      \n"," |      Returns\n"," |      -------\n"," |      self : object\n"," |          Returns an instance of self.\n"," |  \n"," |  ----------------------------------------------------------------------\n"," |  Data and other attributes inherited from BaseSGDClassifier:\n"," |  \n"," |  loss_functions = {'epsilon_insensitive': (<class 'sklearn.linear_model...\n"," |  \n"," |  ----------------------------------------------------------------------\n"," |  Methods inherited from sklearn.linear_model._base.LinearClassifierMixin:\n"," |  \n"," |  decision_function(self, X)\n"," |      Predict confidence scores for samples.\n"," |      \n"," |      The confidence score for a sample is proportional to the signed\n"," |      distance of that sample to the hyperplane.\n"," |      \n"," |      Parameters\n"," |      ----------\n"," |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n"," |          The data matrix for which we want to get the confidence scores.\n"," |      \n"," |      Returns\n"," |      -------\n"," |      scores : ndarray of shape (n_samples,) or (n_samples, n_classes)\n"," |          Confidence scores per `(n_samples, n_classes)` combination. In the\n"," |          binary case, confidence score for `self.classes_[1]` where >0 means\n"," |          this class would be predicted.\n"," |  \n"," |  predict(self, X)\n"," |      Predict class labels for samples in X.\n"," |      \n"," |      Parameters\n"," |      ----------\n"," |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n"," |          The data matrix for which we want to get the predictions.\n"," |      \n"," |      Returns\n"," |      -------\n"," |      y_pred : ndarray of shape (n_samples,)\n"," |          Vector containing the class labels for each sample.\n"," |  \n"," |  ----------------------------------------------------------------------\n"," |  Methods inherited from sklearn.base.ClassifierMixin:\n"," |  \n"," |  score(self, X, y, sample_weight=None)\n"," |      Return the mean accuracy on the given test data and labels.\n"," |      \n"," |      In multi-label classification, this is the subset accuracy\n"," |      which is a harsh metric since you require for each sample that\n"," |      each label set be correctly predicted.\n"," |      \n"," |      Parameters\n"," |      ----------\n"," |      X : array-like of shape (n_samples, n_features)\n"," |          Test samples.\n"," |      \n"," |      y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n"," |          True labels for `X`.\n"," |      \n"," |      sample_weight : array-like of shape (n_samples,), default=None\n"," |          Sample weights.\n"," |      \n"," |      Returns\n"," |      -------\n"," |      score : float\n"," |          Mean accuracy of ``self.predict(X)`` wrt. `y`.\n"," |  \n"," |  ----------------------------------------------------------------------\n"," |  Data descriptors inherited from sklearn.base.ClassifierMixin:\n"," |  \n"," |  __dict__\n"," |      dictionary for instance variables (if defined)\n"," |  \n"," |  __weakref__\n"," |      list of weak references to the object (if defined)\n"," |  \n"," |  ----------------------------------------------------------------------\n"," |  Methods inherited from sklearn.linear_model._base.SparseCoefMixin:\n"," |  \n"," |  densify(self)\n"," |      Convert coefficient matrix to dense array format.\n"," |      \n"," |      Converts the ``coef_`` member (back) to a numpy.ndarray. This is the\n"," |      default format of ``coef_`` and is required for fitting, so calling\n"," |      this method is only required on models that have previously been\n"," |      sparsified; otherwise, it is a no-op.\n"," |      \n"," |      Returns\n"," |      -------\n"," |      self\n"," |          Fitted estimator.\n"," |  \n"," |  sparsify(self)\n"," |      Convert coefficient matrix to sparse format.\n"," |      \n"," |      Converts the ``coef_`` member to a scipy.sparse matrix, which for\n"," |      L1-regularized models can be much more memory- and storage-efficient\n"," |      than the usual numpy.ndarray representation.\n"," |      \n"," |      The ``intercept_`` member is not converted.\n"," |      \n"," |      Returns\n"," |      -------\n"," |      self\n"," |          Fitted estimator.\n"," |      \n"," |      Notes\n"," |      -----\n"," |      For non-sparse models, i.e. when there are not many zeros in ``coef_``,\n"," |      this may actually *increase* memory usage, so use this method with\n"," |      care. A rule of thumb is that the number of zero elements, which can\n"," |      be computed with ``(coef_ == 0).sum()``, must be more than 50% for this\n"," |      to provide significant benefits.\n"," |      \n"," |      After calling this method, further fitting with the partial_fit\n"," |      method (if any) will not work until you call densify.\n"," |  \n"," |  ----------------------------------------------------------------------\n"," |  Methods inherited from sklearn.base.BaseEstimator:\n"," |  \n"," |  __getstate__(self)\n"," |  \n"," |  __repr__(self, N_CHAR_MAX=700)\n"," |      Return repr(self).\n"," |  \n"," |  __setstate__(self, state)\n"," |  \n"," |  get_params(self, deep=True)\n"," |      Get parameters for this estimator.\n"," |      \n"," |      Parameters\n"," |      ----------\n"," |      deep : bool, default=True\n"," |          If True, will return the parameters for this estimator and\n"," |          contained subobjects that are estimators.\n"," |      \n"," |      Returns\n"," |      -------\n"," |      params : dict\n"," |          Parameter names mapped to their values.\n"," |  \n"," |  set_params(self, **params)\n"," |      Set the parameters of this estimator.\n"," |      \n"," |      The method works on simple estimators as well as on nested objects\n"," |      (such as :class:`~sklearn.pipeline.Pipeline`). The latter have\n"," |      parameters of the form ``<component>__<parameter>`` so that it's\n"," |      possible to update each component of a nested object.\n"," |      \n"," |      Parameters\n"," |      ----------\n"," |      **params : dict\n"," |          Estimator parameters.\n"," |      \n"," |      Returns\n"," |      -------\n"," |      self : estimator instance\n"," |          Estimator instance.\n","\n"]}],"source":["# help(SGDClassifier)"]},{"cell_type":"code","execution_count":null,"id":"21e03af1","metadata":{"id":"21e03af1","outputId":"d70dca83-41a8-414e-dca9-f3b5c14df8e4"},"outputs":[{"name":"stdout","output_type":"stream","text":["[[67 38]\n"," [10 64]]\n","tp  67\n","fp  38\n","fn  10\n","tn  64\n"]}],"source":["sgdClassifierModel = SGDClassifier()\n","sgdClassifierModel.fit(X_train, y_train)\n","y_pred = sgdClassifierModel.predict(X_test)\n","\n","conf_matr = confusion_matrix(y_test, y_pred)\n","print(np.flip(conf_matr).T)\n","tn, fp, fn, tp = conf_matr.ravel()\n","print('tp ', tp)\n","print('fp ', fp)\n","print('fn ', fn)\n","print('tn ', tn)"]},{"cell_type":"code","execution_count":null,"id":"65113ca7","metadata":{"id":"65113ca7","outputId":"dfa02ce0-8235-4ba0-adac-b2aeb08e6525"},"outputs":[{"name":"stdout","output_type":"stream","text":["precision is 0.638095238095238\n","recall is  0.8701298701298701\n","accuracy is 0.7318435754189944\n"]}],"source":["precision = tp/ (tp + fp)\n","print('precision is', precision)\n","\n","recall = tp / (tp + fn)\n","print('recall is ', recall)\n","\n","accuracy = (tp + tn) / (tp + tn + fp + fn)\n","print('accuracy is', accuracy)"]},{"cell_type":"code","execution_count":null,"id":"0de4730c","metadata":{"id":"0de4730c"},"outputs":[],"source":["class NeuralNetwork:\n","    def __init__(self, input_nodes, hidden_nodes, hidden_layers, \n","                 output_nodes,  learning_rate):\n","        self.inodes = input_nodes\n","        self.hnodes = hidden_nodes\n","        self.onodes = output_nodes\n","        self.lr = learning_rate\n","        self.node_params = [input_nodes]\n","        \n","        for i in range(hidden_layers):\n","            self.node_params.append(hidden_nodes)\n","            \n","        self.node_params.append(output_nodes)\n","                \n","        self.transition_count = hidden_layers + 1\n","        self.weights = []\n","        self.biases = []\n","        for i in range(self.transition_count):\n","            row, column = self.node_params[i + 1], self.node_params[i]\n","            self.weights.append(\n","                np.random.normal(0.0, pow(column, -0.5), (row, column))\n","            ) \n","            self.biases.append(\n","                np.random.normal(\n","                    0.0 - pow(self.hnodes, -0.5), 0.0 + pow(self.hnodes, -0.5),\n","#                     0.0, pow(row, -0.5),\n","                    (row, 1))\n","            )\n","        self.activation_func = lambda x:scipy.special.expit(x.astype('float'))   \n","        self.epochs = []\n","        self.efficiency = []\n","        self.efficiency_on_train = []\n","        self.outputs = [None] * (self.transition_count + 1)\n","        self.errors = [None] * (self.transition_count + 1)\n","        \n","        \n","        \n","    def train_one_data_set(self, inputs_list, targets_list ):\n","        inputs = np.array(inputs_list, ndmin=2).T\n","        targets = np.array(targets_list, ndmin=2).T\n","       \n","        remarks = []\n","        biases = []\n","        \n","        self.outputs[0] = inputs # zero (pseudo) outputs is an input in NN\n","        for i in range(self.transition_count):\n","            self.outputs[i + 1] = self.activation_func(\n","                np.dot(self.weights[i], self.outputs[i]) + self.biases[i]\n","            )\n","    \n","        self.errors[self.transition_count] = targets - self.outputs[self.transition_count]\n","        for i in reversed(range(self.transition_count)):\n","            self.errors[i] =  np.dot(self.weights[i].T, self.errors[i + 1])\n","        \n","        \n","        for i in reversed(range(self.transition_count)):\n","            remarks.insert(0, self.lr\n","                           * np.dot\n","                           (\n","                (self.errors[i + 1] * self.outputs[i + 1] * (1.0 - self.outputs[i + 1])),\n","                np.transpose(self.outputs[i])\n","                           )\n","            )\n","        \n","        for i in reversed(range(self.transition_count)):\n","            biases.insert(0, self.lr * self.errors[i + 1] \n","                        * self.outputs[i + 1] * (1 - self.outputs[i + 1])\n","                       )\n","        return np.array(remarks, dtype=object), np.array(biases, dtype=object)\n","                    \n","                \n","    def train_one_batch(self, batch, vectored_targets):\n","        weight_remarks, bias_remarks = [], [] #   -    train set\n","        for i, one_train_dataset in enumerate(batch):\n","            one_data_set_remarks, one_data_set_bias_remarks = self.train_one_data_set(one_train_dataset, vectored_targets[i])\n","            weight_remarks.append(one_data_set_remarks)\n","            bias_remarks.append(one_data_set_bias_remarks)\n","            \n","        #       \n","        summed_weight_remarks = np.array(weight_remarks, dtype=object, ndmin=2).sum(axis=0) # like a tensor (batch_size, transition_count, (n,m)-error correction matrix)\n","#         print(len(bias_remarks))\n","        summed_bias_remarks = np.array(bias_remarks, dtype=object, ndmin=2).sum(axis=0)        \n","        \n","        for i, (correct_weights, correct_biases) in enumerate(zip(summed_weight_remarks, summed_bias_remarks)):\n","            self.weights[i] = self.weights[i] + correct_weights\n","            self.biases[i] = self.biases[i] + correct_biases\n","        \n","    def train(self, X, y, test_X, test_y, epochs, batch_size):\n","        self.epochs = []\n","        self.efficiency = []\n","        self.efficiency_on_train = []\n","        for e in range(epochs):\n","            batch_count = int(math.ceil(len(y) / batch_size))\n","            for i in range(batch_count):\n","                batch = X[i * batch_size : (i + 1) * batch_size]\n","                targets = y[i * batch_size : (i + 1) * batch_size]\n","                vectored_targets = [np.zeros(self.onodes) + 0.01 for i in targets]\n","                for target_value, zero_vector in zip(targets, vectored_targets):\n","                    zero_vector[target_value] = 0.99 # max value\n","                self.train_one_batch(batch, vectored_targets)\n","    \n","            self.efficiency.append(self.calc_efficiency(test_X, test_y))\n","            self.efficiency_on_train.append(self.calc_efficiency(X, y))\n","            self.epochs.append(e)\n","                        \n","    def calc_efficiency(self, test_X, test_y):\n","        scorecard = []\n","        for (inputs, outputs) in zip(test_X, test_y):\n","            correct_label = outputs\n","            result = self.query(inputs)\n","            self_label = np.argmax(result)\n","            if correct_label == self_label:\n","                scorecard.append(1)\n","            else:\n","                scorecard.append(0)\n","        \n","        scorecard_array = np.array(scorecard)\n","        return scorecard_array.sum() / scorecard_array.size\n","    \n","    def query(self, inputs):        \n","        outputs = np.array(inputs).reshape((len(inputs), 1))\n","        for i in range(self.transition_count):\n","            inputs = outputs\n","            outputs = self.activation_func(\n","                np.dot(self.weights[i], inputs) \n","                + self.biases[i]\n","            )            \n","        return outputs\n","        "]},{"cell_type":"code","execution_count":null,"id":"0cfd85d2","metadata":{"id":"0cfd85d2","outputId":"f8e559a5-94ee-4b51-db57-170274c64059"},"outputs":[{"data":{"text/plain":["7"]},"execution_count":373,"metadata":{},"output_type":"execute_result"}],"source":["X_train.loc[0].size"]},{"cell_type":"code","execution_count":null,"id":"8da9a76f","metadata":{"id":"8da9a76f"},"outputs":[],"source":["input_nodes = 7\n","hidden_nodes = 300\n","hidden_layers = 3\n","output_nodes = 2\n","learning_rate = 0.01\n","\n","nn = NeuralNetwork(input_nodes, hidden_nodes, hidden_layers,\n","                   output_nodes, learning_rate )\n","nn.train(X_train.values, y_train.values, X_test.values, y_test.values, 100, 1)"]},{"cell_type":"code","execution_count":null,"id":"60072e82","metadata":{"id":"60072e82","outputId":"211ff105-565f-4761-89b4-ac7a20b050be"},"outputs":[{"data":{"text/plain":["array([[31, 16],\n","       [37, 95]], dtype=int64)"]},"execution_count":386,"metadata":{},"output_type":"execute_result"}],"source":["y_pred = []\n","for test in X_test.values:    \n","    res = np.argmax(nn.query(test))\n","    y_pred.append(res)\n","conf_matr = confusion_matrix(y_test, y_pred)\n","np.flip(conf_matr).T"]},{"cell_type":"code","execution_count":null,"id":"99d642fc","metadata":{"id":"99d642fc","outputId":"96213415-12cc-4961-b47f-c0ca1f68465e"},"outputs":[{"name":"stdout","output_type":"stream","text":["tp  31\n","fp  16\n","fn  37\n","tn  95\n","precision is 0.6595744680851063\n","recall is  0.45588235294117646\n","accuracy is 0.7039106145251397\n"]}],"source":["tn, fp, fn, tp = conf_matr.ravel()\n","print('tp ', tp)\n","print('fp ', fp)\n","print('fn ', fn)\n","print('tn ', tn)\n","\n","precision = tp/ (tp + fp)\n","print('precision is', precision)\n","\n","recall = tp / (tp + fn)\n","print('recall is ', recall)\n","\n","accuracy = (tp + tn) / (tp + tn + fp + fn)\n","print('accuracy is', accuracy)"]},{"cell_type":"code","execution_count":null,"id":"bbe9b560","metadata":{"id":"bbe9b560"},"outputs":[],"source":["def min_max_scale(df, columns_name):\n","    for col_name in columns_name:\n","        max_val = df[col_name].max()\n","        min_val = df[col_name].min()\n","        df[col_name] = df[col_name].apply(lambda x : (x - min_val)/ (max_val - min_val))\n","    return df"]},{"cell_type":"code","execution_count":null,"id":"a455519e","metadata":{"id":"a455519e"},"outputs":[],"source":["X_train, X_test = min_max_scale(X_train, ['Age', 'Fare']),  min_max_scale(X_test, ['Age', 'Fare'])"]},{"cell_type":"code","execution_count":null,"id":"c2797011","metadata":{"id":"c2797011","outputId":"95b6b806-7651-45b3-c04c-1b28c81dcfdf"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Age</th>\n","      <th>Embarked</th>\n","      <th>Fare</th>\n","      <th>Parch</th>\n","      <th>Pclass</th>\n","      <th>Sex</th>\n","      <th>SibSp</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>23</th>\n","      <td>0.387900</td>\n","      <td>0.0</td>\n","      <td>0.143422</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>195</th>\n","      <td>0.814947</td>\n","      <td>0.5</td>\n","      <td>0.591953</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>187</th>\n","      <td>0.629893</td>\n","      <td>0.0</td>\n","      <td>0.107264</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>225</th>\n","      <td>0.302491</td>\n","      <td>0.0</td>\n","      <td>0.037775</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>712</th>\n","      <td>0.672598</td>\n","      <td>0.0</td>\n","      <td>0.210083</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>129</th>\n","      <td>0.629893</td>\n","      <td>0.0</td>\n","      <td>0.028179</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>642</th>\n","      <td>0.017794</td>\n","      <td>0.0</td>\n","      <td>0.112718</td>\n","      <td>2</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>518</th>\n","      <td>0.501779</td>\n","      <td>0.0</td>\n","      <td>0.105042</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>78</th>\n","      <td>0.001139</td>\n","      <td>0.0</td>\n","      <td>0.117162</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>714</th>\n","      <td>0.729537</td>\n","      <td>0.0</td>\n","      <td>0.052521</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>179 rows  7 columns</p>\n","</div>"],"text/plain":["          Age  Embarked      Fare  Parch  Pclass  Sex  SibSp\n","23   0.387900       0.0  0.143422      0       1    0      0\n","195  0.814947       0.5  0.591953      0       1    1      0\n","187  0.629893       0.0  0.107264      0       1    0      0\n","225  0.302491       0.0  0.037775      0       3    0      0\n","712  0.672598       0.0  0.210083      0       1    0      1\n","..        ...       ...       ...    ...     ...  ...    ...\n","129  0.629893       0.0  0.028179      0       3    0      0\n","642  0.017794       0.0  0.112718      2       3    1      3\n","518  0.501779       0.0  0.105042      0       2    1      1\n","78   0.001139       0.0  0.117162      2       2    0      0\n","714  0.729537       0.0  0.052521      0       2    0      0\n","\n","[179 rows x 7 columns]"]},"execution_count":453,"metadata":{},"output_type":"execute_result"}],"source":["X_test"]},{"cell_type":"code","execution_count":null,"id":"1d05b236","metadata":{"id":"1d05b236"},"outputs":[],"source":["input_nodes = 7\n","hidden_nodes = 1_000\n","hidden_layers = 0\n","output_nodes = 2\n","learning_rate = 0.1\n","\n","nn = NeuralNetwork(input_nodes, hidden_nodes, hidden_layers,\n","                   output_nodes, learning_rate )\n","nn.train(X_train.values, y_train.values, X_test.values, y_test.values, 15, 10)"]},{"cell_type":"code","execution_count":null,"id":"8ae9cb8a","metadata":{"id":"8ae9cb8a","outputId":"c6381353-96b9-47f8-d9fb-89514e1eb272"},"outputs":[{"name":"stdout","output_type":"stream","text":["179\n","[[51 11]\n"," [21 96]]\n","***********************************\n","tp  51\n","fp  11\n","fn  21\n","tn  96\n","precision is 0.8225806451612904\n","recall is  0.7083333333333334\n","accuracy is 0.8212290502793296\n"]}],"source":["y_pred = []\n","for test in X_test.values:    \n","    res = np.argmax(nn.query(test))\n","    y_pred.append(res)\n","print(len(y_pred))\n","conf_matr = confusion_matrix(y_test, y_pred)\n","print(np.flip(conf_matr).T)\n","print('***********************************')\n","\n","\n","tn, fp, fn, tp = conf_matr.ravel()\n","print('tp ', tp)\n","print('fp ', fp)\n","print('fn ', fn)\n","print('tn ', tn)\n","\n","precision = tp/ (tp + fp)\n","print('precision is', precision)\n","\n","recall = tp / (tp + fn)\n","print('recall is ', recall)\n","\n","accuracy = (tp + tn) / (tp + tn + fp + fn)\n","print('accuracy is', accuracy)"]},{"cell_type":"code","execution_count":null,"id":"6d220867","metadata":{"id":"6d220867"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}